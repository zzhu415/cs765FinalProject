{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> part 1 from email </h1>\n",
    "<h2> determine which features contribute to the components </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "df=pd.read_csv('atussum_1921-reduced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature list and target\n",
    "features = []\n",
    "for i in range(1,17):\n",
    "    features.append('t%02d'%i)\n",
    "\n",
    "features.append('t18')\n",
    "features.append('t50')\n",
    "\n",
    "target = ['TESEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# rows for 2019\n",
    "df_19 = df[df['TUYEAR'] == 2019]\n",
    "# rows for 2021\n",
    "df_21 = df[df['TUYEAR'] == 2021]\n",
    "\n",
    "# selecting cols that only contains the feature\n",
    "x_19 = df_19.loc[:, features]\n",
    "x_21 = df_21.loc[:, features]\n",
    "# normaliza x data returned nparray\n",
    "x_19_scaled = StandardScaler().fit_transform(x_19.values)\n",
    "x_21_scaled = StandardScaler().fit_transform(x_21.values)\n",
    "# reassemble nparray back to dataframe\n",
    "x_19_df = pd.DataFrame(x_19_scaled,index=x_19.index, columns=x_19.columns)\n",
    "x_21_df = pd.DataFrame(x_21_scaled,index=x_21.index, columns=x_21.columns)\n",
    "\n",
    "# selecting target TODO \n",
    "y = df.loc[:,target].values\n",
    "\n",
    "# Deleting original df because we don't need it anymore\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43633019 0.21009205]\n",
      "[0.44347902 0.2161825 ]\n"
     ]
    }
   ],
   "source": [
    "# Perfrom pca\n",
    "pca = PCA(n_components=2)\n",
    "pca_2 = PCA(n_components=2)\n",
    "\n",
    "# 2019\n",
    "pca_19 = pca.fit_transform(x_19)\n",
    "print(pca.explained_variance_ratio_)\n",
    "pca_19_df = pd.DataFrame(data = pca_19\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "# 2021\n",
    "pca_21 = pca_2.fit_transform(x_21)\n",
    "print(pca_2.explained_variance_ratio_)\n",
    "pca_21_df = pd.DataFrame(data = pca_21\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis results from pca\n",
    "dataset_pca_19 = pd.DataFrame(abs(pca.components_),columns=x_19_df.columns,index=['PC_1', 'PC_2'])\n",
    "dataset_pca_21 = pd.DataFrame(abs(pca_2.components_),columns=x_21_df.columns,index=['PC_1', 'PC_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> year 2019 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************** Most important features *************************\n",
      "As per PC 1:\n",
      " t05    0.767699\n",
      "t12    0.625132\n",
      "Name: PC_1, dtype: float64\n",
      "\n",
      "\n",
      "As per PC 2:\n",
      " t01    0.356535\n",
      "t02    0.411126\n",
      "t05    0.470627\n",
      "t12    0.681885\n",
      "Name: PC_2, dtype: float64\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Filter out the feature has higher impact to the component with threshold 0.3\n",
    "print(\"\\n*************** Most important features *************************\")\n",
    "print('As per PC 1:\\n', (dataset_pca_19[dataset_pca_19 > 0.3].iloc[0]).dropna())   \n",
    "print('\\n\\nAs per PC 2:\\n', (dataset_pca_19[dataset_pca_19 > 0.3].iloc[1]).dropna())\n",
    "print(\"\\n******************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> year 2021 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************** Most important features *************************\n",
      "As per PC 1:\n",
      " t05    0.773376\n",
      "t12    0.620138\n",
      "Name: PC_1, dtype: float64\n",
      "\n",
      "\n",
      "As per PC 2:\n",
      " t01    0.301223\n",
      "t02    0.472248\n",
      "t05    0.460071\n",
      "t12    0.676540\n",
      "Name: PC_2, dtype: float64\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Filter out the feature has higher impact to the component with threshold 0.3\n",
    "print(\"\\n*************** Most important features *************************\")\n",
    "print('As per PC 1:\\n', (dataset_pca_21[dataset_pca_21 > 0.3].iloc[0]).dropna())   \n",
    "print('\\n\\nAs per PC 2:\\n', (dataset_pca_21[dataset_pca_21 > 0.3].iloc[1]).dropna())\n",
    "print(\"\\n******************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting no of clusters based on silhoutte score method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimum_n_clusters(data):\n",
    "  n_clusters_candidates = [3,4,5,6,7,8,9,10,12,15,20]\n",
    "  parameter_grid = ParameterGrid({'n_clusters': n_clusters_candidates})\n",
    "\n",
    "  kmeans_model = KMeans() \n",
    "  silhouette_scores = []\n",
    "  best_score = -1\n",
    "\n",
    "  for p in parameter_grid:\n",
    "    kmeans_model.set_params(**p)\n",
    "    kmeans_model.fit(data)\n",
    "\n",
    "    ss = metrics.silhouette_score(data, kmeans_model.labels_)\n",
    "    silhouette_scores += [ss]\n",
    "\n",
    "    if ss > best_score:\n",
    "      best_score = ss\n",
    "      best_grid = p\n",
    "\n",
    "  return best_grid['n_clusters']\n",
    "\n",
    "optimum_clusters_19 = get_optimum_n_clusters(pca_19_df)\n",
    "optimum_clusters_21 = get_optimum_n_clusters(pca_21_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying K-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applyting k means to 2019 data \n",
    "kmeans_19 = KMeans(n_clusters=optimum_clusters_19)\n",
    "kmeans_19.fit(pca_19_df)\n",
    "\n",
    "#Applying k means to 2021 data \n",
    "kmeans_21 = KMeans(n_clusters=optimum_clusters_21)\n",
    "kmeans_21.fit(pca_21_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding K-means labels to df_19 and df_21 for visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19.loc[:, 'cluster_labels'] = kmeans_19.labels_\n",
    "df_21.loc[:, 'cluster_labels'] = kmeans_21.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('misc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7249968e535cdc2c7c6beca6a6497aef5943e1cb7d6e1454e2303dd0759fb3e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
